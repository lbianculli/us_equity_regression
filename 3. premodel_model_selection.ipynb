{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note 10Qs generally release at the end of the following month. \n",
    "# e.g. June financials will be disseminated End of July/Beg. of Aug\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, RepeatedKFold\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "import pickle \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import ensemble, tree, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from preprocessing step\n",
    "premodel_data = pd.read_csv(\"C:/Users/lbianculli/dev/us_equities/ML_categorization/us_data_final_reg.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "premodel_data[\"date_dt\"] = pd.to_datetime(premodel_data[\"period\"], format='%Y-%m-%d')\n",
    "premodel_data[\"ev_to_ebitda\"] = np.where(premodel_data[\"ev_to_ebitda\"] < 0, 100, premodel_data[\"ev_to_ebitda\"])  # this should be moved *\n",
    "\n",
    "# rename columns\n",
    "renamed_cols = [c.replace(\"-\", \"_\") for c in premodel_data.columns]\n",
    "premodel_data.columns = renamed_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Screening\n",
    "Before we get into the premodelling: while we will base investment decisions off the predictions of our model, those predictions should not be treated as a be-all-end-all. One thing we can do to augment our predictions is to bring in an additional quality screen, which we will use to flag potential investments that are low quality, according the measures used by the MSCI Quality Index. These measures will be saved for later, as we still want to train our model including \"low quality\" data points.\n",
    "\n",
    "For more detail on this factor index: https://www.msci.com/documents/10199/4af921f5-0bbc-470b-ad69-19a177fad9cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mstats\n",
    "    \n",
    "# create composite quality score based on leverage, earnings, and ROE (MSCI Quality Index)\n",
    "premodel_data[\"quality_score\"] = (-premodel_data[\"leverage\"] - premodel_data[\"earnings_std\"] + premodel_data[\"roe\"]) / 3\n",
    "quality_screen = premodel_data[\"quality_score\"].quantile(.25)\n",
    "\n",
    "# filter out the bottom quartile and bring back label\n",
    "premodel_data = premodel_data.drop([\"quality_score\", \"date_dt\", \"id\", \"1mo_fwd_log_rets\"], axis=1)\n",
    "\n",
    "# save out quantiles so we can use for final screen\n",
    "with open(\"C:/Users/lbianculli/equity_analysis/quality_screen_2021Q4.p\", \"wb\") as f:\n",
    "    pickle.dump(quality_screen, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Premodel:\n",
    "    plt.rcParams['figure.figsize'] = (8.0, 5.0)\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def train_test_split(self, label, train_size=.8):\n",
    "        \"\"\" \n",
    "        Split processed data into train and test sets. Extract labels. Also stores indexed labels and data in the process.\n",
    "        Data is required to have the label_col column that represents train and test labels.\n",
    "        \"\"\"\n",
    "        # Carve out holdout data\n",
    "        holdout_data = self.data.sample(frac=.2)\n",
    "        non_holdout_data = self.data.drop(holdout_data.index, axis=0)\n",
    "        holdout_labels = holdout_data.pop(label) \n",
    "\n",
    "        # split out train and test from non-holdout data\n",
    "        train_data = non_holdout_data.sample(frac=.8)\n",
    "        test_data = non_holdout_data.drop(train_data.index, axis=0)\n",
    "\n",
    "        train_labels = train_data.pop(label).reset_index(drop=True)\n",
    "        test_labels = test_data.pop(label).reset_index(drop=True)\n",
    "        \n",
    "        # turn back into dataframes\n",
    "        train_data = pd.DataFrame(data=train_data, columns=[c for c in self.data.columns if c != label]).reset_index(drop=True)\n",
    "        assert(\"label\" not in train_data.columns)\n",
    "\n",
    "        test_data = pd.DataFrame(data=test_data, columns=[c for c in self.data.columns if c != label]).reset_index(drop=True)\n",
    "        \n",
    "        holdout_data = pd.DataFrame(data=holdout_data, columns=[c for c in self.data.columns if c != label]).reset_index(drop=True)\n",
    "\n",
    "        return train_data, test_data, holdout_data, train_labels, test_labels, holdout_labels\n",
    "\n",
    "    def pca_transform(self, train_data, test_data, n_components):\n",
    "        \"\"\" take train data and apply PCA. We do this so we always train on the same records \"\"\"\n",
    "        pca = PCA(n_components)\n",
    "        pca_train_data = pca.fit_transform(train_data)\n",
    "        pca_test_data = pca.fit_transform(test_data)\n",
    "\n",
    "        return pca_train_data, pca_test_data, pca\n",
    "\n",
    "    def run_grid(self, clf, grid, train_data, test_data, train_labels, test_labels, n_jobs=-1, score=\"accuracy\"):\n",
    "        \"\"\" \n",
    "        Runs SKLearn implementation of grid search \n",
    "        clf: un-fit SKLearn classifier\n",
    "        grid: params upon which grid search will run\n",
    "        data: pandas DataFrame of model data, inclusive of label\n",
    "        label: name of column that holds classification labels\n",
    "\n",
    "        returns: Most accurate model\n",
    "        \"\"\"\n",
    "        grid_search = GridSearchCV(estimator=clf, param_grid=grid, n_jobs=n_jobs, scoring=score)\n",
    "        best_clf = grid_search.fit(train_data, train_labels).best_estimator_\n",
    "\n",
    "        # get model predictions and accuracy\n",
    "        preds = best_clf.predict(test_data)\n",
    "        acc = metrics.accuracy_score(preds, test_labels)\n",
    "\n",
    "        print(f\"Model Accuracy: {acc*100:.1f}%\")\n",
    "\n",
    "        return best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Feature selection is the process of identifying and selecting a subset of input variables that have the most predictive power in forecasting the target variable. The most popular feature selection technique that can be used for regression problems is to calculate the correlation each feature has with the target and take the features with the highest values.\n",
    "\n",
    "We will follow this approach and then compare to a baseline model to determine efficacy for this dataset.\n",
    "\n",
    "For more on feature selection for regression models: https://machinelearningmastery.com/feature-selection-for-regression-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of correlation feature selection for numerical data\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test, fs_func=f_regression):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_regression, k=25)\n",
    "    \n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    \n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    \n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    \n",
    "    return X_train_fs, X_test_fs, fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAEvCAYAAAC6xJMcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXjUlEQVR4nO3dcayd9X3f8fcndkJJOhQIF8RsmIlkpQW0kHLF3GWqstAOp0Qx/yA5Woq1MXlCrEumSq29/DH1D0tIm6oWaTChJMWsWZCXJsMKJYvlFlWTaMglYSEGPNxA4Q4Xu5mysEYihX73x/mRnNjHvudc33vP/fm8X9LR8zzf8/ye8zu/e+753Oc5z3luqgpJktSXt027A5IkaXIGuCRJHTLAJUnqkAEuSVKHDHBJkjpkgEuS1KGN0+7AUi699NLasmXLtLshSdKaePLJJ/+qquaWWm/dB/iWLVtYWFiYdjckSVoTSf5inPU8hC5JUocMcEmSOmSAS5LUIQNckqQOGeCSJHXIAJckqUMGuCRJHTLAJUnqkAEuSVKHDHBJkjpkgEuS1KF1fy10nf+27Hnkx/Mv3n3LFHsiSf1wD1ySpA4Z4JIkdcgAlySpQwa4JEkdMsC17mzZ88hPndgmSTqdAS5JUocMcEmSOrRkgCd5X5Knhm4/SPKpJJckOZTk+Ta9eKjN3iTHkhxNcvNQ/YYkT7f77kmS1XpikiSdz5YM8Ko6WlXXV9X1wA3AD4EvA3uAw1W1FTjclklyDbATuBbYDtybZEPb3H3AbmBru21f0WcjSdKMmPQQ+k3An1fVXwA7gP2tvh+4tc3vAB6qqter6gXgGHBjkiuAi6rq8aoq4MGhNpIkaQKTBvhO4Att/vKqOg7Qppe1+ibg5aE2i622qc2fWpckSRMaO8CTvAP4GPBfl1p1RK3OUh/1WLuTLCRZOHny5LhdlCRpZkyyB/4R4JtV9WpbfrUdFqdNT7T6InDlULvNwCutvnlE/TRVdX9VzVfV/Nzc3ARdlCRpNkwS4B/nJ4fPAQ4Cu9r8LuDhofrOJBckuZrByWpPtMPsryXZ1s4+v32ojSRJmsBY/040yTuBXwH+5VD5buBAkjuAl4DbAKrqSJIDwDPAG8BdVfVma3Mn8ABwIfBou0mSpAmNFeBV9UPgPafUvsfgrPRR6+8D9o2oLwDXTd5NSZI0zCuxSZLUIQNckqQOGeCSJHXIAJckqUMGuCRJHTLAJUnqkAEuSVKHDHBJkjpkgEuS1CEDXJKkDhngkiR1yACXJKlDBrgkSR0ywCVJ6pABLklShwxwSZI6ZIBLktQhA1ySpA4Z4JIkdcgAlySpQwa4JEkdMsAlSeqQAS5JUocMcEmSOmSAS5LUIQNckqQOGeCSJHVorABP8u4kX0zyXJJnk/xikkuSHEryfJtePLT+3iTHkhxNcvNQ/YYkT7f77kmS1XhSkiSd78bdA/894KtV9XPA+4FngT3A4araChxuyyS5BtgJXAtsB+5NsqFt5z5gN7C13bav0POQJGmmLBngSS4Cfgn4LEBV/aiqvg/sAPa31fYDt7b5HcBDVfV6Vb0AHANuTHIFcFFVPV5VBTw41EaSJE1gnD3w9wIngd9P8q0kn0nyLuDyqjoO0KaXtfU3AS8PtV9stU1t/tT6aZLsTrKQZOHkyZMTPSFJkmbBOAG+EfgF4L6q+gDw17TD5Wcw6nPtOkv99GLV/VU1X1Xzc3NzY3RRkqTZMk6ALwKLVfX1tvxFBoH+ajssTpueGFr/yqH2m4FXWn3ziLokSZrQkgFeVX8JvJzkfa10E/AMcBDY1Wq7gIfb/EFgZ5ILklzN4GS1J9ph9teSbGtnn98+1EaSJE1g45jr/Trw+STvAL4L/DMG4X8gyR3AS8BtAFV1JMkBBiH/BnBXVb3ZtnMn8ABwIfBou0mSpAmNFeBV9RQwP+Kum86w/j5g34j6AnDdBP2TJEkjeCU2SZI6ZIBLktQhA1ySpA4Z4JIkdcgAlySpQwa4JEkdMsAlSeqQAS5JUocMcEmSOmSAS5LUIQNckqQOGeCSJHXIAJckqUMGuCRJHTLAJUnqkAEuSVKHDHBJkjpkgEuS1CEDXJKkDhngkiR1yACXJKlDBrgkSR0ywCVJ6pABLklShwxwSZI6ZIBLktShsQI8yYtJnk7yVJKFVrskyaEkz7fpxUPr701yLMnRJDcP1W9o2zmW5J4kWfmnJEnS+W+SPfB/XFXXV9V8W94DHK6qrcDhtkySa4CdwLXAduDeJBtam/uA3cDWdtt+7k9BkqTZcy6H0HcA+9v8fuDWofpDVfV6Vb0AHANuTHIFcFFVPV5VBTw41EaSJE1g3AAv4GtJnkyyu9Uur6rjAG16WatvAl4earvYapva/Kl1SZI0oY1jrvfBqnolyWXAoSTPnWXdUZ9r11nqp29g8EfCboCrrrpqzC5KkjQ7xtoDr6pX2vQE8GXgRuDVdlicNj3RVl8Erhxqvhl4pdU3j6iPerz7q2q+qubn5ubGfzaSJM2IJQM8ybuS/J235oF/AnwHOAjsaqvtAh5u8weBnUkuSHI1g5PVnmiH2V9Lsq2dfX77UBtJkjSBcQ6hXw58uX3jayPwX6rqq0m+ARxIcgfwEnAbQFUdSXIAeAZ4A7irqt5s27oTeAC4EHi03SRJ0oSWDPCq+i7w/hH17wE3naHNPmDfiPoCcN3k3ZQkScO8EpskSR0ywCVJ6pABLklShwxwSZI6ZIBLktQhA1ySpA4Z4JIkdcgAlySpQwa4JEkdMsAlSeqQAS5JUocMcEmSOmSAS5LUIQNckqQOGeCSJHXIAJckqUMGuCRJHTLAJUnqkAEuSVKHNk67A9Jq2LLnkR/Pv3j3LVPsiSStDvfAJUnqkHvgktQBjyrpVO6BS5LUIQNckqQOGeCSJHXIAJckqUNjB3iSDUm+leQrbfmSJIeSPN+mFw+tuzfJsSRHk9w8VL8hydPtvnuSZGWfjiRJs2GSPfBPAs8OLe8BDlfVVuBwWybJNcBO4FpgO3Bvkg2tzX3AbmBru20/p95LkjSjxgrwJJuBW4DPDJV3APvb/H7g1qH6Q1X1elW9ABwDbkxyBXBRVT1eVQU8ONRGkiRNYNw98N8FfhP426Ha5VV1HKBNL2v1TcDLQ+stttqmNn9qXZIkTWjJAE/yUeBEVT055jZHfa5dZ6mPeszdSRaSLJw8eXLMh5UkaXaMswf+QeBjSV4EHgI+nOQPgFfbYXHa9ERbfxG4cqj9ZuCVVt88on6aqrq/quaran5ubm6CpyNJ0mxYMsCram9Vba6qLQxOTvvjqvoEcBDY1VbbBTzc5g8CO5NckORqBierPdEOs7+WZFs7+/z2oTaSJGkC53It9LuBA0nuAF4CbgOoqiNJDgDPAG8Ad1XVm63NncADwIXAo+0mSZImNFGAV9VjwGNt/nvATWdYbx+wb0R9Abhu0k5KkqSf5pXYJEnqkAEuSVKHDHBJkjpkgEuS1CEDXJKkDhngkiR1yACXJKlDBrgkSR0ywCVJ6pABLklShwxwSZI6ZIBLktQhA1ySpA4Z4JIkdcgAlySpQwa4JEkdMsAlSeqQAS5JUocMcEmSOmSAS5LUIQNckqQOGeCSJHXIAJckqUMGuCRJHTLAJUnqkAEuSVKHlgzwJD+T5Ikk/zPJkSS/3eqXJDmU5Pk2vXiozd4kx5IcTXLzUP2GJE+3++5JktV5WpIknd/G2QN/HfhwVb0fuB7YnmQbsAc4XFVbgcNtmSTXADuBa4HtwL1JNrRt3QfsBra22/aVeyqSJM2OJQO8Bv5fW3x7uxWwA9jf6vuBW9v8DuChqnq9ql4AjgE3JrkCuKiqHq+qAh4caiNJkiYw1mfgSTYkeQo4ARyqqq8Dl1fVcYA2vaytvgl4eaj5YqttavOn1iVJ0oTGCvCqerOqrgc2M9ibvu4sq4/6XLvOUj99A8nuJAtJFk6ePDlOFyVJmikTnYVeVd8HHmPw2fWr7bA4bXqirbYIXDnUbDPwSqtvHlEf9Tj3V9V8Vc3Pzc1N0kVJkmbCOGehzyV5d5u/EPhl4DngILCrrbYLeLjNHwR2JrkgydUMTlZ7oh1mfy3Jtnb2+e1DbSRJ0gQ2jrHOFcD+dib524ADVfWVJI8DB5LcAbwE3AZQVUeSHACeAd4A7qqqN9u27gQeAC4EHm03SZI0oSUDvKq+DXxgRP17wE1naLMP2DeivgCc7fNzSZI0Bq/EJklShwxwSZI6ZIBLktQhA1ySpA4Z4JIkdcgAlySpQwa4JEkdMsAlSeqQAS5JUocMcEmSOmSAS5LUIQNckqQOGeCSJHXIAJckqUMGuCRJHTLAJUnqkAEuSVKHDHBJkjpkgEuS1CEDXJKkDhngkiR1yACXJKlDBrgkSR0ywCVJ6pABLklShwxwSZI6tHHaHZhlW/Y88uP5F+++ZYo9kST1Zsk98CRXJvmTJM8mOZLkk61+SZJDSZ5v04uH2uxNcizJ0SQ3D9VvSPJ0u++eJFmdpyVJ0vltnEPobwC/UVU/D2wD7kpyDbAHOFxVW4HDbZl2307gWmA7cG+SDW1b9wG7ga3ttn0Fn4skaQlb9jzy45v6tmSAV9Xxqvpmm38NeBbYBOwA9rfV9gO3tvkdwENV9XpVvQAcA25McgVwUVU9XlUFPDjURpIkTWCik9iSbAE+AHwduLyqjsMg5IHL2mqbgJeHmi222qY2f2p91OPsTrKQZOHkyZOTdFGSpJkwdoAn+VngD4FPVdUPzrbqiFqdpX56ser+qpqvqvm5ublxuyhJ0swYK8CTvJ1BeH++qr7Uyq+2w+K06YlWXwSuHGq+GXil1TePqEuSpAmNcxZ6gM8Cz1bV7wzddRDY1eZ3AQ8P1XcmuSDJ1QxOVnuiHWZ/Lcm2ts3bh9pIkqQJjPM98A8CvwY8neSpVvu3wN3AgSR3AC8BtwFU1ZEkB4BnGJzBfldVvdna3Qk8AFwIPNpukiRpQksGeFX9D0Z/fg1w0xna7AP2jagvANdN0kFJknQ6L6Wqc+L3SSVpOgxwSZI6ZIBLktQhA1ySpA4Z4JIkdcgAlySpQwa4JEkdMsAlSeqQAS5JUocMcEmSOmSAS5LUIQNckqQOGeCSJHXIAJckqUMGuCRJHVry/4FL0jQN/7vaF+++ZYo9kdYX98AlSeqQAS7pnGzZ88hP7SVLWhseQu+QhxQ1Tb7+pPXBPXBJkjrkHrhWjHtmkrR23AOXJKlDBrimwhOfJOncGOCaCf7BIOl8Y4BLktQhA1ySpA4tGeBJPpfkRJLvDNUuSXIoyfNtevHQfXuTHEtyNMnNQ/Ubkjzd7rsnSVb+6Wg98bC1ZtVbr31f/1pN4+yBPwBsP6W2BzhcVVuBw22ZJNcAO4FrW5t7k2xobe4DdgNb2+3UbUqSpDEt+T3wqvrTJFtOKe8APtTm9wOPAb/V6g9V1evAC0mOATcmeRG4qKoeB0jyIHAr8Og5PwNpBflddkm9WO5n4JdX1XGANr2s1TcBLw+tt9hqm9r8qXVJkibixxMDK30ltlGfa9dZ6qM3kuxmcLidq666amV6pi65RyxJoy13D/zVJFcAtOmJVl8ErhxabzPwSqtvHlEfqarur6r5qpqfm5tbZhclSTp/LTfADwK72vwu4OGh+s4kFyS5msHJak+0w+yvJdnWzj6/faiNJEma0JKH0JN8gcEJa5cmWQT+HXA3cCDJHcBLwG0AVXUkyQHgGeAN4K6qerNt6k4GZ7RfyODkNU9gkyRpmcY5C/3jZ7jrpjOsvw/YN6K+AFw3Ue8kSdJIXolNkqQOGeCSJHXIAJe07vg9X2lpBrgkSR1a6Qu5aBV4MZPxvDVOszBGq/2a8DXXN39+s8EAl6Q1dGq4GrZaLg+hS5LUIffApTXk3pakleIeuCRJHUrVGf8p2LowPz9fCwsLK7vRD31oRTf3Z9/93o/nt733PSve7tT1lvt4q+Gtvozq1/B9y203yXNdbl9GbWOcdZdjpbY/zX4ud2yX8/jr7fU+ruWM36h1x93muTx+j1bjNXdOHntsRTeX5Mmqml9qPQ+hr7Dz4ZdDkrT+zdwe+Gp8BnmmC04stf1x+7Kez1od/urWmfo5qo/jtpvkuS63L6O2Mc66y7FS2z/bdlbiMSbZ/mp8fW+5r4H1YjnjN2rdcbd5Lo/fo/P9K6PugUs6L96sJY1mgK9TXkZSq81wl/rmWeiSJHXIPfAZ5d7XuVntcyn8max/Z/ssW1oLBvh5bLmBYJBorfmam9xaj9n5fuJYjwxwaYrca1OP/INrfTDAJWmVrdc/1NZzELvHvzQDfBlW6vuY6st6fROeNb6xSwMGuNaEf8hI0soywAW4dylJvTHAzzMGsaRha3H0q/dL3/bKAJdWgG9aktaaAa6JzFJQzdJz1U/4c1cvDPAZ4uF1aTKG+bnzWwOrZ80DPMl24PeADcBnqurute7D+cQ3mPVnPf9M1tMfcb6xr5z1/Job1ks/e7GmAZ5kA/AfgV8BFoFvJDlYVc+sZT+WYz298Wn2+ManteZrbv1b6z3wG4FjVfVdgCQPATuAdR/gWh/ca1s9/pGq9foa8I+J0dY6wDcBLw8tLwL/YI37MJZp/aOAtXq8SazX0FyJMVvLr9jMgrON51r8B7czfZ1p2Lk89mr/LNfz+8Bqm+Y/X+p13FNVa/dgyW3AzVX1L9ryrwE3VtWvn7LebmB3W3wfcHSFu3Ip8FcrvM3zgeMymuMymuNyOsdkNMdltDONy9+rqrmlGq/1HvgicOXQ8mbglVNXqqr7gftXqxNJFqpqfrW23yvHZTTHZTTH5XSOyWiOy2jnOi5vW8nOjOEbwNYkVyd5B7ATOLjGfZAkqXtrugdeVW8k+VfAf2fwNbLPVdWRteyDJEnngzX/HnhV/RHwR2v9uKdYtcPznXNcRnNcRnNcTueYjOa4jHZO47KmJ7FJkqSVsdafgUuSpBUwcwGeZHuSo0mOJdkz7f5MQ5Irk/xJkmeTHEnyyVa/JMmhJM+36cXT7us0JNmQ5FtJvtKWZ35ckrw7yReTPNdeN7/ouECSf9N+h76T5AtJfmYWxyXJ55KcSPKdodoZxyHJ3vYefDTJzdPp9eo6w5j8+/Y79O0kX07y7qH7Jh6TmQrwoUu5fgS4Bvh4kmum26upeAP4jar6eWAbcFcbhz3A4araChxuy7Pok8CzQ8uOy+D/F3y1qn4OeD+D8ZnpcUmyCfjXwHxVXcfgxNydzOa4PABsP6U2chzae81O4NrW5t723ny+eYDTx+QQcF1V/X3gfwF7YfljMlMBztClXKvqR8Bbl3KdKVV1vKq+2eZfY/BmvInBWOxvq+0Hbp1KB6coyWbgFuAzQ+WZHpckFwG/BHwWoKp+VFXfZ8bHpdkIXJhkI/BOBte1mLlxqao/Bf7PKeUzjcMO4KGqer2qXgCOMXhvPq+MGpOq+lpVvdEW/4zBtVBgmWMyawE+6lKum6bUl3UhyRbgA8DXgcur6jgMQh64bIpdm5bfBX4T+Nuh2qyPy3uBk8Dvt48WPpPkXcz4uFTV/wb+A/AScBz4v1X1NWZ8XIacaRx8Hx7458CjbX5ZYzJrAZ4RtZk9DT/JzwJ/CHyqqn4w7f5MW5KPAieq6slp92Wd2Qj8AnBfVX0A+Gtm47DwWbXPdHcAVwN/F3hXkk9Mt1ddmPn34SSfZvBR5uffKo1YbckxmbUAH+tSrrMgydsZhPfnq+pLrfxqkiva/VcAJ6bVvyn5IPCxJC8y+Hjlw0n+AMdlEVisqq+35S8yCPRZH5dfBl6oqpNV9TfAl4B/iOPyljONw0y/DyfZBXwU+Kf1k+9xL2tMZi3AvZQrkCQMPs98tqp+Z+iug8CuNr8LeHit+zZNVbW3qjZX1RYGr40/rqpP4Lj8JfBykve10k0M/gXwTI8Lg0Pn25K8s/1O3cTgfJJZH5e3nGkcDgI7k1yQ5GpgK/DEFPq35pJsB34L+FhV/XDoruWNSVXN1A34VQZn//058Olp92dKY/CPGBye+TbwVLv9KvAeBmeLPt+ml0y7r1Mcow8BX2nzMz8uwPXAQnvN/DfgYselAH4beA74DvCfgQtmcVyALzA4D+BvGOxN3nG2cQA+3d6DjwIfmXb/13BMjjH4rPut993/dC5j4pXYJEnq0KwdQpck6bxggEuS1CEDXJKkDhngkiR1yACXJKlDBrgkSR0ywCVJ6pABLklSh/4/R06yzlIRmqEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning features: 116\n",
      "Reduced features 30\n"
     ]
    }
   ],
   "source": [
    "# setup premodel class\n",
    "pm = Premodel(data=premodel_data)\n",
    "\n",
    "# split train, test, and holdout data along with sample weights\n",
    "train_data, test_data, holdout_data, train_labels, test_labels, holdout_labels = pm.train_test_split(label=\"fwd_fcf_per_share\")\n",
    "# train_sample_weights = get_sample_weights(train_labels)  # what is this for?\n",
    "\n",
    "# keep test and holdout tickers for look-forward analysis after training model\n",
    "train_data = train_data.drop([\"ticker\", \"period\"], axis=1)\n",
    "test_tickers = test_data.pop(\"ticker\")\n",
    "test_dates = test_data.pop(\"period\")\n",
    "holdout_tickers = holdout_data.pop(\"ticker\")\n",
    "holdout_tickers = holdout_data.pop(\"period\")\n",
    "\n",
    "# perform feature selection\n",
    "train_features, test_features, fs_func = select_features(train_data, train_labels, test_data)\n",
    "\n",
    "# find mean score\n",
    "scores = pd.Series(fs_func.scores_).replace(np.nan, np.median(fs_func.scores_))\n",
    "mean_score = np.mean(scores)\n",
    "\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(scores))], scores)\n",
    "plt.hlines(y=mean_score, xmin=0, xmax=len(scores), color=\"r\")\n",
    "plt.show()\n",
    "\n",
    "# find features with importan\n",
    "feat_scores_df = pd.DataFrame(zip(train_data.columns, scores), columns=[\"feature\", \"imp\"]).set_index(\"feature\")\n",
    "features_to_keep = feat_scores_df.loc[feat_scores_df[\"imp\"] > mean_score].index\n",
    "\n",
    "print(f\"Beginning features: {train_data.shape[1]}\\nReduced features {train_data[features_to_keep].shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>volatility</th>\n",
       "      <td>536.601247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1mo_rets</th>\n",
       "      <td>0.715404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1mo_log_rets</th>\n",
       "      <td>0.006710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1yr_rets</th>\n",
       "      <td>26.682699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1yr_log_rets</th>\n",
       "      <td>69.283203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     imp\n",
       "feature                 \n",
       "volatility    536.601247\n",
       "1mo_rets        0.715404\n",
       "1mo_log_rets    0.006710\n",
       "1yr_rets       26.682699\n",
       "1yr_log_rets   69.283203"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the importance scores for each of our features. We will reduce the feature set to include only features with mean importance or higher. Then we will compare our model using the reduced feature set to a baseline model to determine if it should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.277\n"
     ]
    }
   ],
   "source": [
    "### Reduced Dataset\n",
    "# fit the base model\n",
    "model = LinearRegression()\n",
    "model.fit(train_data[features_to_keep], train_labels)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(test_data[features_to_keep])\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(test_labels, yhat)\n",
    "print(f'MAE: {mae:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.272\n"
     ]
    }
   ],
   "source": [
    "### Unpaired Dataset\n",
    "# fit the base model\n",
    "model = LinearRegression()\n",
    "model.fit(train_data, train_labels)\n",
    "\n",
    "# evaluate the model\n",
    "yhat = model.predict(test_data)\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(test_labels, yhat)\n",
    "print(f'MAE: {mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model did not actually improve using feature selection, so we will go forward with the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/lbianculli/dev/us_equities/reg_train_data.p\", \"wb\") as f:\n",
    "    pickle.dump([train_data, test_data, holdout_data, train_labels, test_labels, holdout_labels], f)\n",
    "\n",
    "# write out feature set for live use \n",
    "with open(\"C:/Users/lbianculli/dev/us_equities/ML_categorization/important_features.p\", \"wb\") as f:\n",
    "     pickle.dump(train_data.columns, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our Model\n",
    "\n",
    "We are going to used a Stacked Generalization (stacking) regressor with the help of SKLearn. A stacked generalization model utilizes a meta-learning algorithm to learn how to best combine the predictions from base machine learning algorithms.\n",
    "\n",
    "For more information on Stacking models: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n",
    "\n",
    "TODO:\n",
    "- Grid search on base models\n",
    "- explore dataset features more\n",
    "- visualizations: test_performance (boxplot, anything else?)\n",
    "- build out commentary/documentation (start with Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "def get_stacking_model(n_splits=5):\n",
    "    \"\"\" Create a stacked ensemble of our models \"\"\"\n",
    "    # define base models\n",
    "    l0 = [\n",
    "        (\"knn\", KNeighborsRegressor()), \n",
    "        (\"cart\", DecisionTreeRegressor()),\n",
    "        (\"svm\", SVR()),\n",
    "        (\"linear\", LinearRegression())]\n",
    "    \n",
    "    # define meta-learner\n",
    "    l1 = RandomForestRegressor(n_estimators=500)\n",
    "    \n",
    "    # create stacking ensemble\n",
    "    model = StackingRegressor(estimators=l0, final_estimator=l1, cv=n_splits)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# start with a list of base models\n",
    "def get_models():\n",
    "    models = {\n",
    "        \"knn\": KNeighborsRegressor(), \n",
    "        \"cart\": DecisionTreeRegressor(),\n",
    "        \"svm\": SVR(),\n",
    "        \"linear\": LinearRegression(), \n",
    "        \"stacking\": get_stacking_model()}\n",
    "    \n",
    "    return models\n",
    "\n",
    "def eval_model(model, x, y, n_splits=5):\n",
    "    \"\"\" evaluate model using cross-validation \"\"\" \n",
    "    # create CV object and calculate scores\n",
    "    cv = RepeatedKFold(n_splits=n_splits, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, x, y, scoring=\"neg_mean_absolute_error\", cv=cv, n_jobs=1)\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "We have now defined our base and meta (stacking) models. The next step is to evaluate the base models in isolation before running data through our stacking model. If our stacking model performs better on the train data, we will go forward with that model. Otherwise we will use whichever model performs the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get models\n",
    "models = get_models()\n",
    "\n",
    "# store models and results\n",
    "results, names = [], []\n",
    "\n",
    "# evaluate models\n",
    "best_score = np.inf\n",
    "best_model = None\n",
    "\n",
    "# iterate through model instances to find the best model\n",
    "for name, model in models.items():\n",
    "    scores = eval_model(model, train_data, train_labels)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print(f\"{name.upper()}: {np.mean(scores):.2f} ({np.std(scores):.2f})\")\n",
    "    \n",
    "    if np.mean(scores) < best_score:\n",
    "        best_score = np.mean(scores)\n",
    "        best_model = model\n",
    "    \n",
    "# plot performance of each model\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/lbianculli/dev/us_equities/stacked_regression.p\", \"rb\") as f:\n",
    "    best_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>FLR</td>\n",
       "      <td>2013-9</td>\n",
       "      <td>0.157029</td>\n",
       "      <td>-0.241499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>FLR</td>\n",
       "      <td>2015-3</td>\n",
       "      <td>0.514248</td>\n",
       "      <td>0.335257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>FLR</td>\n",
       "      <td>2015-6</td>\n",
       "      <td>0.298602</td>\n",
       "      <td>1.320721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>FLR</td>\n",
       "      <td>2017-3</td>\n",
       "      <td>0.084368</td>\n",
       "      <td>0.195563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>FLR</td>\n",
       "      <td>2019-12</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>-0.677179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker     date      pred     label\n",
       "6489    FLR   2013-9  0.157029 -0.241499\n",
       "6490    FLR   2015-3  0.514248  0.335257\n",
       "6491    FLR   2015-6  0.298602  1.320721\n",
       "6492    FLR   2017-3  0.084368  0.195563\n",
       "6493    FLR  2019-12  0.001037 -0.677179"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the best model and evaluate test results. TODO: plot?\n",
    "best_model.fit(train_data, train_labels)\n",
    "test_preds = best_model.predict(test_data).flatten()\n",
    "test_results = pd.concat([test_tickers, test_dates, pd.Series(test_preds), pd.Series(test_labels)], axis=1)\n",
    "test_results.columns = [\"ticker\", \"date\", \"pred\", \"label\"]\n",
    "\n",
    "test_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite model now that it is trained\n",
    "with open(\"C:/Users/lbianculli/dev/us_equities/stacked_regression_trained.p\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Data\n",
    "\n",
    "The model is finalized... almost. Before we start to use the model on a go-forward basis, the first thing we need to do is test it on the holdout data. We did a lot of work premodeling and tuning our model. By holding out data and evaluating the model on that data, we can be reasonably confident that we have not overfit if the model continues to perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout MAE: 0.238\n"
     ]
    }
   ],
   "source": [
    "holdout_preds = best_model.predict(holdout_data).flatten()\n",
    "holdout_mae = mean_absolute_error(holdout_labels, holdout_preds)\n",
    "\n",
    "print(f\"Holdout MAE: {holdout_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the holdouts MAE is actually better than our train/test metrics. A good sign!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Past Performance\n",
    "With our fancy new model, lets perform one last sanity check: let's see how investments would have performed were we too follow the advice of our model during the last quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def analyze_preds(df, date=\"2021-6\", top_n=20):\n",
    "    current_data = df.loc[df[\"date\"] == date]\n",
    "    current_data = current_data.sort_values(\"pred\", ascending=False)\n",
    "\n",
    "    # get largest and smallest companies to achieve some cap exposure\n",
    "    current_tickers = list(current_data.head(top_n)[\"ticker\"])\n",
    "\n",
    "    # get returns for each ticker\n",
    "    #TODO: make date dynamic (e.g. dates)\n",
    "    rets = {}\n",
    "    for ticker in current_tickers: \n",
    "        ticker_obj = yf.Ticker(ticker)\n",
    "        \n",
    "        # we wont have data until a month later\n",
    "        ticker_data = ticker_obj.history(start='2021-07-30', end='2021-10-30')\n",
    "        ticker_data[\"rets\"] = ticker_data[\"Close\"].pct_change()\n",
    "        ticker_data = ticker_data.dropna()\n",
    "        cum_rets = (ticker_data[\"rets\"] + 1).cumprod() - 1\n",
    "\n",
    "        # store ticker's cumulative returns\n",
    "        rets[ticker] = cum_rets[-1]\n",
    "\n",
    "    # get final return values\n",
    "    all_rets = np.array(list(rets.values()))\n",
    "\n",
    "    # get cumulative return of SPY for comparison\n",
    "    ticker_obj = yf.Ticker(\"SPY\")\n",
    "    \n",
    "    # we wont have data until a month later\n",
    "    spy_data = ticker_obj.history(start='2021-07-30', end='2021-10-30')\n",
    "    spy_data[\"rets\"] = spy_data[\"Close\"].pct_change()\n",
    "    spy_data = spy_data.dropna()\n",
    "\n",
    "    spy_mean_ret = spy_data[\"rets\"].mean()\n",
    "\n",
    "    # get SPY cumulative returns\n",
    "    spy_cum_rets = (spy_data[\"rets\"] + 1).cumprod() - 1\n",
    "    spy_cum_rets[-1]\n",
    "\n",
    "    print(f\"SPY returned {spy_cum_rets[-1]*100:.2f}%\")\n",
    "    print(f\"Theoretical Portfolio returned {np.mean(all_rets)*100:.2f}%\")\n",
    "    \n",
    "    return all_rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY returned 5.07%\n",
      "Theoretical Portfolio returned -0.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.30108942, -0.02508576, -0.07989515, -0.07821697, -0.15162748,\n",
       "        0.01603328, -0.34704182,  0.17188976,  0.00879845,  0.14217238])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_preds(test_results, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our portfolio would have decent last quarter. It is important to note that this does not guarentee future performance. It is clear that the model/hypotehsis is far from infallible, as there is a security we would have invested in that returned -10% last quarter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
